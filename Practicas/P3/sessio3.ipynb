{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f0b320a",
   "metadata": {},
   "source": [
    "# Sessió 3: Boosting Classifier Model\n",
    "\n",
    "La sessió consisteix en crear un boosting classifier amb _decision trees_ de la llibreria sklearn com a _weak model_. \n",
    "\n",
    "Boosting (https://en.wikipedia.org/wiki/Boosting_(machine_learning)): tècnica d'aprenentatge automàtic que consiteix en entrenar múltiples models (_weak models_) seqüencialment per obtenir un model general _strong model_. Podem definir un _weak learner_ o _weak model_ com un classificador el qual està lleugerament correlacionat amb problema final i que és millor que intentar-ho encertar aleatòriament, és a dir, que no ha de veure tot el problema sener. La idea és que cada _weak model_ es centra en una feature concreta o en arreglar els errors del classificador anterior.\n",
    "\n",
    "En essència, el _boosting_ respon a la pregunta següent:\n",
    "\n",
    "```Can a set of weak learners create a strong single learner? ```\n",
    "\n",
    "La resposta a aquesta pregunta es **sí**, i ho veurem en aquesta sessió.\n",
    "\n",
    "En el cas concret dels **classificadors** el que hem d'aconseguir és el següent: \n",
    "```\n",
    "[...] most boosting algorithms consist of iteratively learning weak classifiers with respect to a distribution and adding them to a final strong classifier. When they are added, they are weighted in a way that is related to the weak learners' accuracy. After a weak learner is added, the data weights are readjusted, known as \"re-weighting\". Misclassified input data gain a higher weight and examples that are classified correctly lose weight.[note 1] Thus, future weak learners focus more on the examples that previous weak learners misclassified._\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bda4d9",
   "metadata": {},
   "source": [
    "## Context\n",
    "\n",
    "El dataset en qüestió (https://www.kaggle.com/datasets/anmolkumar/health-insurance-cross-sell-prediction) és un dataset d'assegurançes, el qual vol predir si els seus actuals clients estarien interessats en també adquirir una *assegurança de cotxe*. És a dir, de cilents ja existents d'una asseguradora, quina és la probabilitat de que els hi interessi adquirir una assegurança de cotxe per al seu vehicle. Anem a explorar el Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42573017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(304887, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Driving_License</th>\n",
       "      <th>Region_Code</th>\n",
       "      <th>Previously_Insured</th>\n",
       "      <th>Vehicle_Age</th>\n",
       "      <th>Vehicle_Damage</th>\n",
       "      <th>Annual_Premium</th>\n",
       "      <th>Policy_Sales_Channel</th>\n",
       "      <th>Vintage</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>339630</td>\n",
       "      <td>Male</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt; 1 Year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>44470.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>240794</td>\n",
       "      <td>Male</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2630.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>124429</td>\n",
       "      <td>Male</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2630.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>171989</td>\n",
       "      <td>Male</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>36332.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>257</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>327313</td>\n",
       "      <td>Male</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>42764.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id Gender  Age  Driving_License  Region_Code  Previously_Insured  \\\n",
       "0  339630   Male   21                1         28.0                   0   \n",
       "1  240794   Male   45                1         28.0                   0   \n",
       "2  124429   Male   71                1         41.0                   0   \n",
       "3  171989   Male   41                1         49.0                   0   \n",
       "4  327313   Male   77                1         28.0                   0   \n",
       "\n",
       "  Vehicle_Age Vehicle_Damage  Annual_Premium  Policy_Sales_Channel  Vintage  \\\n",
       "0    < 1 Year            Yes         44470.0                 152.0       11   \n",
       "1    1-2 Year            Yes          2630.0                  26.0       45   \n",
       "2    1-2 Year            Yes          2630.0                   7.0       11   \n",
       "3    1-2 Year            Yes         36332.0                 124.0      257   \n",
       "4    1-2 Year            Yes         42764.0                 122.0      298   \n",
       "\n",
       "   Response  \n",
       "0         1  \n",
       "1         0  \n",
       "2         0  \n",
       "3         1  \n",
       "4         0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Generate Baseline solution with a RandomForest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('data/train_project3.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b72bdfb",
   "metadata": {},
   "source": [
    "Fem una petita investigació de les classes de resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7da643dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de zeros: 267573, percentual: 87.76%\n",
      "Total de uns: 37314, percentual: 12.24%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = df[\"Response\"].value_counts()\n",
    "response.plot(kind='bar', color=['blue', 'red'])\n",
    "\n",
    "zeros, ones = response[0]/df.shape[0], response[1]/df.shape[0]\n",
    "\n",
    "print(f\"Total de zeros: {response[0]}, percentual: {round(zeros,4)*100}%\")\n",
    "print(f\"Total de uns: {response[1]}, percentual: {round(ones,4)*100}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878c24fe",
   "metadata": {},
   "source": [
    "És a dir, ens trobem davant del que es diu un dataset desequilibrat, o bé un _imabalanced dataset_, on hi ha moltes més observacions d'una classe o de l'altra. En general, aquest no és un cas ideal ja que pot portar a diferents problemes. Hi ha múltiples maneres de solucionar-ho, i a la pràctica us demanem que ho arregleu amb una _Weighted Binary Cross Entropy_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca35805",
   "metadata": {},
   "source": [
    "## Binary Cross Entropy o Log Loss\n",
    "\n",
    "En binari ens referim al tipus de classifició entre dues classes. Per el model saber com de bé està classificant entre les dues classes, mira a l'espai n-dimensional de característiques com de lluny està el valor que ha donat a una observació. Aquesta \"distància\" és el que s'anomena la _loss function_, que en el cas de la classificació binària és\n",
    "\n",
    "$L_B = -\\cfrac{1}{N} \\sum_{i=0}^N[y_i log(p_i) + (1-y_i)log(1-p_i)]$, on $N$ són les observacions, $y_i$ és el valor de veritat i $p_i$ és la probabilitat predita per la mostra $i$\n",
    "\n",
    "Concretament (i com es desil·la de l'expressió) la formula calcula la pèrdua (com de lluny s'ha quedat la precció) comparant la probabilitat predita amb el valor real de l'observació, per tant, com més lluny està la predicció de la veritat, pitjor pèrdua té i més gran és el valor de la funció.\n",
    "\n",
    "Transpira de l'explicació doncs, que si tenim moltes més mostres d'una classe que de l'altra el valor de la funció de pèrdua queda esbiaixat cap a la predicció d'una classe.\n",
    "\n",
    "## Weighted Binary Cross Entropy\n",
    "\n",
    "La idea és equilibrar el desbalançeig de mostres afegint un coeficient que faci que la pèrdua de la classe minoritària tingui més pes que no la de la classe majoritària:\n",
    "\n",
    "$L_{WB} = -\\cfrac{1}{N} \\sum_{i=0}^N[w_1 y_i log(p_i) + w_0 (1-y_i)log(1-p_i)]; w_0 +w_1 = 1$\n",
    "\n",
    "On $w_1$ és el pes de la classe majoritària i $w_0$ és el pes de la classe minoritària. El pesos han de ser inversament proporcionals a les freqüències de les classes, ergo tenint la classe minoritària (1) un pes més gran que la majoritària (0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd9d1c1",
   "metadata": {},
   "source": [
    "## Baseline\n",
    "\n",
    "Una _baseline_ és una procediment de _benchmarking_ per comparar com el teu model funciona. Aquests han de ser senzills i ràpids d'implementar, i no tenen perque ser molt millors que endevinar aleatòriament la resposta. S'usen per comparar amb els que hem de programar, de manera que vegem que el _boosting_ està millorant una aproximació ingènua dins de l'aprenentatge automàtic i per jutjar si val la pena!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "050b9fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9967135364905686\n",
      "Precision: 0.9951186255794928\n",
      "Recall: 0.9779439352521841\n",
      "F1: 0.9864565311418686\n",
      "ROC AUC: 0.9886374794677204\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# import data\n",
    "train = pd.read_csv('data/train_project3.csv',)\n",
    "test = pd.read_csv('data/test_project3.csv')\n",
    "\n",
    "#train the model -> this is a baseline, only the simple features are used\n",
    "model = RandomForestClassifier()\n",
    "X = train[['Age','Driving_License','Annual_Premium','Vintage','Region_Code']]\n",
    "y = train['Response']\n",
    "model.fit(X,y)\n",
    "y_train = model.predict(X)\n",
    "\n",
    "accuracy = accuracy_score(y, y_train)\n",
    "precision = precision_score(y, y_train)\n",
    "recall = recall_score(y, y_train)\n",
    "f1 = f1_score(y, y_train)\n",
    "roc_auc = roc_auc_score(y, y_train)\n",
    "\n",
    "# evaluate the test set\n",
    "X_test = test[['Age', 'Driving_License', 'Annual_Premium', 'Vintage', 'Region_Code']]\n",
    "y_test = model.predict(X_test)\n",
    "\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1: {f1}\")\n",
    "print(f\"ROC AUC: {roc_auc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382e2f35",
   "metadata": {},
   "source": [
    "### PREGUNTA EXTRA: és el nostre model bo? Fa falta mirar-nos més el problema si ja tenim mètriques tan bones? És l'accuracy suficient o fa falta alguna altra mètrica? Què passaria si fessim servir l'F1 score en comptes de l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3b3abf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save our predictions in the Kaggle formats\n",
    "# evaluate the test set\n",
    "X_test = test[['Age', 'Driving_License', 'Annual_Premium', 'Vintage', 'Region_Code']]\n",
    "y_test = model.predict(X_test)\n",
    "\n",
    "\n",
    "test['Response'] = y_test\n",
    "test[['id','Response']].to_csv('my_solution.csv',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1bf0b5",
   "metadata": {},
   "source": [
    "# Tasques\n",
    "\n",
    "1. Completeu la classe _BoostingClassifier_ i els seus dos mètodes _fit_ i _predict_ com veieu més adhient per obtenir els millors resultats al Dataset.\n",
    "2. Implementeu la funció *balance_weights* per veure quin pes assigna a cada vector.\n",
    "\n",
    "La idea és que trobeu quin calcul d'error, quin learning rate i quin estil de predicció dona millors resultats, també com quin repartiment de pesos balançeja millor el dataset. \n",
    "\n",
    "NOTA: per a que el resultat sigui el millor possible podeu tractar el dataset amb les eines apreses a les sessions 1 i 2 (tractament de categòriques, mirar correlacions, estratificar el train i test...).\n",
    "\n",
    "3. Penjeu els millors resultats al Kaggle!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb09d42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "class BoostingClassifier:\n",
    "    def __init__(self, X: np.array, y: np.array, w: np.array):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.weights = w / w.sum()  # Normalize initial weights\n",
    "        self.n = X.shape[0]\n",
    "        self.trees = []  # Store weak learners\n",
    "        self.learning_rates = []\n",
    "        \n",
    "    #Entrena el clasificador amb un número especific de models debils (num_trees).\n",
    "\n",
    "    def fit(self, num_trees, shrinkage=1.0, factor=1.0):\n",
    "        for m in range(num_trees):\n",
    "            # Se entrena un model debil\n",
    "            tree = DecisionTreeClassifier(max_depth=5)\n",
    "            tree.fit(self.X, self.y, sample_weight=self.weights)\n",
    "            predictions = tree.predict(self.X)\n",
    "\n",
    "            # Calcular les mostres mal clasificades\n",
    "            misclassified = predictions != self.y\n",
    "\n",
    "            #Calcular l'error de l'arbre\n",
    "            error = np.sum(self.weights * misclassified) / np.sum(self.weights)\n",
    "\n",
    "            #Actualitzar els pesos segons la predicció del model debil\n",
    "            alpha = shrinkage * np.log((1 - error) / error)\n",
    "            self.weights *= np.exp(alpha * misclassified)\n",
    "\n",
    "            #Calcular el Learning Rate\n",
    "            learning_rate = factor / (1.0 + m)\n",
    "            self.learning_rates.append(learning_rate)\n",
    "\n",
    "            #Emmagatzemar el model debil y el seu pes\n",
    "            self.trees.append((tree, alpha))\n",
    "            \n",
    "    #Realitza predicciones utilitzant el clasificador\n",
    "    def predict(self, X):\n",
    "        \n",
    "        result = np.zeros(X.shape[0])\n",
    "        \n",
    "        #Combina les prediccions de tots els models debils sumant les prediccions ponderades.\n",
    "        for tree, alpha in self.trees:\n",
    "            result += alpha * tree.predict(X)\n",
    "            \n",
    "        #Arrodoneix el resultat per obtenir predicciones binarias.\n",
    "        result_binary = np.round(result)\n",
    "        return result_binary\n",
    "    \n",
    "def balance_weights(responses: list):\n",
    "    unique_classes, counts = np.unique(responses, return_counts=True)\n",
    "    #Calcular els pesos de clase, sent inversament proporcionals a las frequencies\n",
    "    class_weights = 1.0 / counts\n",
    "    balanced = np.zeros(len(responses))\n",
    "    \n",
    "    #Assignar pesos a cada instancia basant-se en la seva classe\n",
    "    for i, c in enumerate(unique_classes):\n",
    "        balanced[responses == c] = class_weights[i]\n",
    "        \n",
    "    #Es retorna els pesos balancejats. \n",
    "    return balanced\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3af0eefa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tudu11/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/Users/tudu11/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6001180753714455\n",
      "Precision: 0.9026673507935531\n",
      "Recall: 0.6001180753714455\n",
      "F1: 0.672716248281961\n",
      "ROC AUC: 0.7795280683653147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tudu11/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Cargar los datos\n",
    "df = pd.read_csv('data/train_project3.csv')\n",
    "\n",
    "# 1. Manejo de la variable 'Vehicle_Age'\n",
    "df['Vehicle_Age'] = df['Vehicle_Age'].replace({'< 1 Year': 0, '1-2 Year': 1, '> 2 Years': 2})\n",
    "\n",
    "# 2. Codificación de variables categóricas (por ejemplo, 'Gender' y 'Vehicle_Damage')\n",
    "encoder = OneHotEncoder(sparse=False, drop='first')\n",
    "categorical_columns = ['Gender', 'Vehicle_Damage']\n",
    "for column in categorical_columns:\n",
    "    encoded_values = encoder.fit_transform(df[[column]])\n",
    "    encoded_columns = [f\"{column}_{i}\" for i in range(encoded_values.shape[1])]\n",
    "    df = pd.concat([df, pd.DataFrame(encoded_values, columns=encoded_columns)], axis=1)\n",
    "    df.drop(columns=[column], inplace=True)\n",
    "\n",
    "# 3. Manejo de correlaciones\n",
    "correlation_matrix = df.corr().abs()\n",
    "upper_tri = correlation_matrix.where(np.triu(np.ones(correlation_matrix.shape), k=1).astype(np.bool_))\n",
    "to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.8)]\n",
    "df.drop(columns=to_drop, inplace=True)\n",
    "\n",
    "# 4. División del conjunto de datos\n",
    "X = df.drop(columns=['Response'])\n",
    "y = df['Response']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# 6. Entrenar el modelo\n",
    "initial_weights = balance_weights(y_train)\n",
    "# Instantiate BoostingClassifier without the 'factor' parameter\n",
    "bc = BoostingClassifier(X_train, y_train, initial_weights)\n",
    "# Call the fit method\n",
    "bc.fit(30, shrinkage=0.1, factor=1.55)\n",
    "\n",
    "# 7. Realizar predicciones\n",
    "y_pred = bc.predict(X_test)\n",
    "\n",
    "# 8. Evaluar el modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "roc_auc = roc_auc_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "\n",
    "# Mostrar métricas\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1: {f1}\")\n",
    "print(f\"ROC AUC: {roc_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcb063a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniform Weights - Accuracy: 0.7169634950309948\n",
      "Uniform Weights - Precision: 0.8866555429786178\n",
      "Uniform Weights - Recall: 0.7169634950309948\n",
      "Uniform Weights - F1: 0.7651173835754816\n",
      "Uniform Weights - ROC AUC: 0.7727750748696958\n"
     ]
    }
   ],
   "source": [
    "# Exemple d'inicialització amb pesos uniformes\n",
    "initial_weights_uniform = np.ones_like(y_train) / len(y_train)\n",
    "bc_uniform = BoostingClassifier(X_train, y_train, initial_weights_uniform)\n",
    "bc_uniform.fit(30, shrinkage=0.1, factor=1.55)\n",
    "y_pred_uniform = bc_uniform.predict(X_test)\n",
    "\n",
    "# Assegura't que les prediccions i les etiquetes tinguin la mateixa longitud\n",
    "y_test_uniform = y_test[:len(y_pred_uniform)]\n",
    "\n",
    "# Avalua el rendiment\n",
    "accuracy_uniform = accuracy_score(y_test_uniform, y_pred_uniform)\n",
    "precision_uniform = precision_score(y_test_uniform, y_pred_uniform, average='weighted')\n",
    "recall_uniform = recall_score(y_test_uniform, y_pred_uniform, average='weighted')\n",
    "f1_uniform = f1_score(y_test_uniform, y_pred_uniform, average='weighted')\n",
    "roc_auc_uniform = roc_auc_score(y_test_uniform, y_pred_uniform, average='weighted')\n",
    "\n",
    "# Imprimeix o mostra les mètriques\n",
    "print(f\"Uniform Weights - Accuracy: {accuracy_uniform}\")\n",
    "print(f\"Uniform Weights - Precision: {precision_uniform}\")\n",
    "print(f\"Uniform Weights - Recall: {recall_uniform}\")\n",
    "print(f\"Uniform Weights - F1: {f1_uniform}\")\n",
    "print(f\"Uniform Weights - ROC AUC: {roc_auc_uniform}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f9d4878",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tudu11/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# save our predictions in the Kaggle formats\n",
    "# evaluate the test set\n",
    "test = pd.read_csv('data/test_project3.csv')\n",
    "\n",
    "# 1. Manejo de la variable 'Vehicle_Age'\n",
    "test['Vehicle_Age'] = test['Vehicle_Age'].replace({'< 1 Year': 0, '1-2 Year': 1, '> 2 Years': 2})\n",
    "\n",
    "# 2. Manejo de la variable 'Vehicle_Damage'\n",
    "test = test.drop(columns=['Vehicle_Damage'])\n",
    "\n",
    "# 3. Codificación de variables categóricas (por ejemplo, 'Gender')\n",
    "encoder = OneHotEncoder(sparse=False, drop='first')\n",
    "categorical_columns = ['Gender']\n",
    "for column in categorical_columns:\n",
    "    encoded_values = encoder.fit_transform(test[[column]])\n",
    "    encoded_columns = [f\"{column}_{i}\" for i in range(encoded_values.shape[1])]\n",
    "    test = pd.concat([test, pd.DataFrame(encoded_values, columns=encoded_columns)], axis=1)\n",
    "    test.drop(columns=[column], inplace=True)\n",
    "\n",
    "\n",
    "    \n",
    "y_test = bc.predict(test)\n",
    "\n",
    "test['Response'] = y_test\n",
    "test[['id', 'Response']].to_csv('my_solution.csv', index=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5be013",
   "metadata": {},
   "source": [
    "# Preguntes\n",
    "Per acabar, contesteu les següents preguntes:\n",
    "1. Quines mètriques heu fet servir per avaluar els models? Com depenen aquestes mètriques segons el balanç del model?\n",
    "2. Prova d'inicialitzar el model amb els pesos a $1/n$. Hi ha diferència entre pesos uniformes o cambiants per classe?\n",
    "3. Descriu breument l'estratègia d'actualitzar pesos, calcul d'errors, calcul de learning rate i predicció final. Investiga quines són les estratègies que utilitza el model AdaBoost i discuteix com de similars són les teves.\n",
    "4. Distuteix i compara els resultats amb els següents models de baseline: RandomForest, Bagging i AdaBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3703072",
   "metadata": {},
   "source": [
    "# --- Respostes Preguntes ---\n",
    "## 1.\n",
    "\n",
    "He utilitzat diverses mètriques per avaluar els models, i aquí hi ha algunes de les mètriques clau esmentades en els resultats:\n",
    "- Accuracy (Precisió): Mesura la proporció de prediccions correctes al conjunt de dades.En un conjunt de dades balancejat, es una mètrica informativa però en un desbalancejat pot ser enganyosa ja que un model que prediu sempre la classe majoritària pot tenir una alta accuracy, però no proporciona informació útil sobre la capacitat del model per predir la classe minoritària.\n",
    "\n",
    "- Precision (Precisió): Mesura la proporció d'instàncies positives correctament predites entre totes les instàncies que el model va predir com a positives. En un conjunt de dades desbalancejat pot ser alta inclus si un modle prediu poques instancies positives verdaderes, ja que es centra en les prediccions posotives.\n",
    "\n",
    "- Recall (Recuperació o Sensibilitat): Mesura la proporció d'instàncies positives correctament predites entre totes les instàncies positives reals. En un conjunt de dades desbalancejat pot ser baix si el model tendeix a prediure la clase majoritaria, ja que es centre en instancies positives reals.\n",
    "\n",
    "- F1-Score: És la mitjana harmònica de precisió i recall. Proporciona un equilibri entre precisió i recall. \n",
    "\n",
    "- ROC AUC (Àrea sota la corba ROC): Mesura la capacitat del model per distingir entre classes positives i negatives. Com més gran sigui el ROC AUC, millor és el model en aquest aspecte. No es veu afectat per el desbalancement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5080063",
   "metadata": {},
   "source": [
    "## 2. \n",
    "Sí, hi ha diferència entre inicialitzar el model amb pesos uniformes (1/𝑛) i inicialitzar-lo amb pesos cambiants per classe. A continuació, es destaquen algunes de les principals diferències observades en les mètriques:\n",
    "\n",
    "Pesos Uniformes (1/𝑛):\n",
    "\n",
    "Accuracy: 60.0%\n",
    "\n",
    "Precision: 90.3%\n",
    "\n",
    "Recall: 60.0%\n",
    "\n",
    "F1 Score: 67.3%\n",
    "\n",
    "ROC AUC: 77.95%\n",
    "\n",
    "Pesos Cambiants per Classe:\n",
    "\n",
    "Accuracy: 71.7%\n",
    "\n",
    "Precision: 88.7%\n",
    "\n",
    "Recall: 71.7%\n",
    "\n",
    "F1 Score: 76.5%\n",
    "\n",
    "ROC AUC: 77.28%\n",
    "\n",
    "Amb pesos cambiants per classe, s'observa una millora en l'accuracy, el recall i l'F1 score en comparació amb els pesos uniformes. Això indica que la inicialització dels pesos influeix en el rendiment del model. En aquest cas, els pesos cambiants per classe semblen millorar la capacitat del model per identificar correctament les instàncies positives (recall) sense sacrificar excessivament la precision.\n",
    "\n",
    "En resum, la tria de com inicialitzar els pesos pot tenir un impacte significatiu en el rendiment del model de boosting, i és important ajustar-ho segons les característiques específiques del conjunt de dades i els objectius del model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a3df16",
   "metadata": {},
   "source": [
    "## 3.\n",
    "\n",
    "L'estratègia de boosting implica l'entrenament iteratiu de models febles amb la finalitat de millorar el rendiment global d'un model fort. Aquí està la descripció general de l'estratègia d'actualització de pesos, el càlcul d'errors, el càlcul de learning rate i la predicció final:\n",
    "\n",
    "#### Entrenament de Models Febles:\n",
    "\n",
    "Es comença amb la inicialització d'uns pesos per a cada observació del conjunt de dades.\n",
    "S'entrena un model feble (com un arbre de decisió amb poca profunditat) utilitzant aquest conjunt de dades amb pesos actualitzats.\n",
    "\n",
    "El model feble es centra en corregir els errors dels models anteriors o en donar importància a les instàncies mal classificades.\n",
    "\n",
    "#### Càlcul d'Errors:\n",
    "\n",
    "Després de l'entrenament del model feble, es calcula l'error en comparació amb les etiquetes reals.\n",
    "Les instàncies mal classificades tenen un pes més gran en el càlcul de l'error.\n",
    "\n",
    "#### Actualització de Pesos:\n",
    "\n",
    "Es calcula un factor d'actualització de pesos basat en l'error del model feble. Aquest factor s'utilitza per donar més pes a les instàncies mal classificades i menys pes a les instàncies correctament classificades.\n",
    "Els pesos actualitzats es multipliquen pel factor d'actualització.\n",
    "\n",
    "#### Càlcul de Learning Rate:\n",
    "\n",
    "Es calcula el learning rate, que és un factor que controla la contribució de cada model feble al model global.\n",
    "El learning rate redueix la contribució de cada model per evitar sobreajustar el conjunt d'entrenament.\n",
    "\n",
    "#### Predicció Final:\n",
    "\n",
    "Es combinen els models febles entrenats mitjançant la suma ponderada de les seves prediccions.\n",
    "Els models que tenen un rendiment millor reben més pes en la predicció final, mentre que els que tenen un rendiment pitjor reben menys pes.\n",
    "\n",
    "Pel que fa a AdaBoost, és un algoritme de boosting que utilitza una estratègia similar, però amb algunes diferències notables:\n",
    "\n",
    "Pesos Inicials: AdaBoost inicialitza els pesos com a 1/n, on n és el nombre d'observacions.\n",
    "\n",
    "Actualització de Pesos: Els pesos es redueixen per a les observacions que s'han classificat correctament i s'incrementen per a les mal classificades. Els pesos actualitzats estan relacionats amb l'error del model.\n",
    "\n",
    "Càlcul de Learning Rate: El learning rate s'ajusta en cada iteració basant-se en l'error del model actual.\n",
    "\n",
    "Predicció Final: La predicció final és la suma ponderada de les prediccions dels models febles, cada una multiplicant-se pel seu pes.\n",
    "\n",
    "Tot i que l'estratègia general és similar, l'ús específic de pesos, la manera de calcular-los i d'ajustar-los pot variar entre diferents implementacions de boosting. Les diferències es destaquen en com s'assignen i actualitzen els pesos, com es calcula el learning rate i com es combinen les prediccions finals. La teva implementació de boosting pot tenir algunes variacions en comparació amb AdaBoost, especialment si has adaptat el mètode segons les teves necessitats específiques.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9034c72f",
   "metadata": {},
   "source": [
    "## 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc6a29d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest - Training Set:\n",
      "Accuracy: 0.9971423768700622\n",
      "Precision: 0.9958579479866911\n",
      "Recall: 0.9807737319022303\n",
      "F1: 0.988258284058557\n",
      "ROC AUC: 0.9901018218861064\n",
      "\n",
      "RandomForest - Test Set:\n",
      "Accuracy: 0.8651808849093116\n",
      "Precision: 0.21134751773049645\n",
      "Recall: 0.04023221277170244\n",
      "F1: 0.06759668821594646\n",
      "ROC AUC: 0.509737356689187\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Importar datos\n",
    "train = pd.read_csv('data/train_project3.csv')\n",
    "test = pd.read_csv('data/test_project3.csv')\n",
    "\n",
    "#train the model -> this is a baseline, only the simple features are used\n",
    "X = train[['Age', 'Driving_License', 'Annual_Premium', 'Vintage', 'Region_Code']]\n",
    "y = train['Response']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "precision_train = precision_score(y_train, y_train_pred)\n",
    "recall_train = recall_score(y_train, y_train_pred)\n",
    "f1_train = f1_score(y_train, y_train_pred)\n",
    "roc_auc_train = roc_auc_score(y_train, y_train_pred)\n",
    "\n",
    "\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "precision_test = precision_score(y_test, y_test_pred)\n",
    "recall_test = recall_score(y_test, y_test_pred)\n",
    "f1_test = f1_score(y_test, y_test_pred)\n",
    "roc_auc_test = roc_auc_score(y_test, y_test_pred)\n",
    "\n",
    "# Imprimir métricas\n",
    "print(\"RandomForest - Training Set:\")\n",
    "print(f\"Accuracy: {accuracy_train}\")\n",
    "print(f\"Precision: {precision_train}\")\n",
    "print(f\"Recall: {recall_train}\")\n",
    "print(f\"F1: {f1_train}\")\n",
    "print(f\"ROC AUC: {roc_auc_train}\")\n",
    "\n",
    "print(\"\\nRandomForest - Test Set:\")\n",
    "print(f\"Accuracy: {accuracy_test}\")\n",
    "print(f\"Precision: {precision_test}\")\n",
    "print(f\"Recall: {recall_test}\")\n",
    "print(f\"F1: {f1_test}\")\n",
    "print(f\"ROC AUC: {roc_auc_test}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f95be639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost Classifier - Training Set:\n",
      "Accuracy: 0.8778273864433047\n",
      "Precision: 0.652542372881356\n",
      "Recall: 0.007723944227104022\n",
      "F1: 0.015267175572519085\n",
      "ROC AUC: 0.5035745916217809\n",
      "\n",
      "Adaboost Classifier - Test Set:\n",
      "Accuracy: 0.8778083899111155\n",
      "Precision: 0.23809523809523808\n",
      "Recall: 0.0027001485081679494\n",
      "F1: 0.005339741022560406\n",
      "ROC AUC: 0.5007527361420457\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Importar datos\n",
    "train = pd.read_csv('data/train_project3.csv')\n",
    "test = pd.read_csv('data/test_project3.csv')\n",
    "\n",
    "#train the model -> this is a baseline, only the simple features are used\n",
    "X = train[['Age', 'Driving_License', 'Annual_Premium', 'Vintage', 'Region_Code']]\n",
    "y = train['Response']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "base_model = DecisionTreeClassifier(max_depth=5)\n",
    "adaboost_model = AdaBoostClassifier(base_model, n_estimators=30, random_state=42)\n",
    "\n",
    "\n",
    "adaboost_model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = adaboost_model.predict(X_train)\n",
    "y_test_pred = adaboost_model.predict(X_test)\n",
    "\n",
    "\n",
    "accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "precision_train = precision_score(y_train, y_train_pred)\n",
    "recall_train = recall_score(y_train, y_train_pred)\n",
    "f1_train = f1_score(y_train, y_train_pred)\n",
    "roc_auc_train = roc_auc_score(y_train, y_train_pred)\n",
    "\n",
    "\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "precision_test = precision_score(y_test, y_test_pred)\n",
    "recall_test = recall_score(y_test, y_test_pred)\n",
    "f1_test = f1_score(y_test, y_test_pred)\n",
    "roc_auc_test = roc_auc_score(y_test, y_test_pred)\n",
    "\n",
    "# Imprimir métricas\n",
    "print(\"Adaboost Classifier - Training Set:\")\n",
    "print(f\"Accuracy: {accuracy_train}\")\n",
    "print(f\"Precision: {precision_train}\")\n",
    "print(f\"Recall: {recall_train}\")\n",
    "print(f\"F1: {f1_train}\")\n",
    "print(f\"ROC AUC: {roc_auc_train}\")\n",
    "\n",
    "print(\"\\nAdaboost Classifier - Test Set:\")\n",
    "print(f\"Accuracy: {accuracy_test}\")\n",
    "print(f\"Precision: {precision_test}\")\n",
    "print(f\"Recall: {recall_test}\")\n",
    "print(f\"F1: {f1_test}\")\n",
    "print(f\"ROC AUC: {roc_auc_test}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07cb02c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Classifier - Training Set:\n",
      "Accuracy: 0.615368846578027\n",
      "Precision: 0.21380206000895657\n",
      "Recall: 0.7981743404554118\n",
      "F1: 0.3372634345175442\n",
      "ROC AUC: 0.6939979654539188\n",
      "\n",
      "Bagging Classifier - Test Set:\n",
      "Accuracy: 0.6057266555151039\n",
      "Precision: 0.1999783573206363\n",
      "Recall: 0.7484811664641555\n",
      "F1: 0.3156276686592656\n",
      "ROC AUC: 0.6672349271868294\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Importar datos\n",
    "train = pd.read_csv('data/train_project3.csv')\n",
    "test = pd.read_csv('data/test_project3.csv')\n",
    "\n",
    "#train the model -> this is a baseline, only the simple features are used\n",
    "X = train[['Age', 'Driving_License', 'Annual_Premium', 'Vintage', 'Region_Code']]\n",
    "y = train['Response']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "base_model = DecisionTreeClassifier(max_depth=10, class_weight='balanced', random_state=42)\n",
    "bagging_model = BaggingClassifier(base_model, n_estimators=50, random_state=42)\n",
    "\n",
    "\n",
    "bagging_model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = bagging_model.predict(X_train)\n",
    "y_test_pred = bagging_model.predict(X_test)\n",
    "\n",
    "\n",
    "accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "precision_train = precision_score(y_train, y_train_pred)\n",
    "recall_train = recall_score(y_train, y_train_pred)\n",
    "f1_train = f1_score(y_train, y_train_pred)\n",
    "roc_auc_train = roc_auc_score(y_train, y_train_pred)\n",
    "\n",
    "\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "precision_test = precision_score(y_test, y_test_pred)\n",
    "recall_test = recall_score(y_test, y_test_pred)\n",
    "f1_test = f1_score(y_test, y_test_pred)\n",
    "roc_auc_test = roc_auc_score(y_test, y_test_pred)\n",
    "\n",
    "# Imprimir métricas\n",
    "print(\"Bagging Classifier - Training Set:\")\n",
    "print(f\"Accuracy: {accuracy_train}\")\n",
    "print(f\"Precision: {precision_train}\")\n",
    "print(f\"Recall: {recall_train}\")\n",
    "print(f\"F1: {f1_train}\")\n",
    "print(f\"ROC AUC: {roc_auc_train}\")\n",
    "\n",
    "print(\"\\nBagging Classifier - Test Set:\")\n",
    "print(f\"Accuracy: {accuracy_test}\")\n",
    "print(f\"Precision: {precision_test}\")\n",
    "print(f\"Recall: {recall_test}\")\n",
    "print(f\"F1: {f1_test}\")\n",
    "print(f\"ROC AUC: {roc_auc_test}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49337f5",
   "metadata": {},
   "source": [
    "En resum, aquets son els resultats:\n",
    "\n",
    "# Random forest\n",
    "### RandomForest - Training Set:\n",
    "\n",
    "Accuracy: 0.9971423768700622\n",
    "\n",
    "Precision: 0.9958579479866911\n",
    "\n",
    "Recall: 0.9807737319022303\n",
    "\n",
    "F1: 0.988258284058557\n",
    "\n",
    "ROC AUC: 0.9901018218861064\n",
    "\n",
    "### RandomForest - Test Set:\n",
    "Accuracy: 0.8651808849093116\n",
    "\n",
    "Precision: 0.21134751773049645\n",
    "\n",
    "Recall: 0.04023221277170244\n",
    "\n",
    "F1: 0.06759668821594646\n",
    "\n",
    "ROC AUC: 0.509737356689187\n",
    "\n",
    "# Adaboost classifier\n",
    "\n",
    "### Adaboost Classifier - Training Set:\n",
    "Accuracy: 0.8778273864433047\n",
    "\n",
    "Precision: 0.652542372881356\n",
    "\n",
    "Recall: 0.007723944227104022\n",
    "\n",
    "F1: 0.015267175572519085\n",
    "\n",
    "ROC AUC: 0.5035745916217809\n",
    "\n",
    "### Adaboost Classifier - Test Set:\n",
    "Accuracy: 0.8778083899111155\n",
    "\n",
    "Precision: 0.23809523809523808\n",
    "\n",
    "Recall: 0.0027001485081679494\n",
    "\n",
    "F1: 0.005339741022560406\n",
    "\n",
    "ROC AUC: 0.5007527361420457\n",
    "\n",
    "# Bagging classifier\n",
    "\n",
    "### Bagging Classifier - Training Set:\n",
    "Accuracy: 0.615368846578027\n",
    "\n",
    "Precision: 0.21380206000895657\n",
    "\n",
    "Recall: 0.7981743404554118\n",
    "\n",
    "F1: 0.3372634345175442\n",
    "\n",
    "ROC AUC: 0.6939979654539188\n",
    "\n",
    "### Bagging Classifier - Test Set:\n",
    "Accuracy: 0.6057266555151039\n",
    "\n",
    "Precision: 0.1999783573206363\n",
    "\n",
    "Recall: 0.7484811664641555\n",
    "\n",
    "F1: 0.3156276686592656\n",
    "\n",
    "ROC AUC: 0.6672349271868294"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae671073",
   "metadata": {},
   "source": [
    "Una vegada tenim tots els resultats podem comparar-los amb el BoostingClassifier que hem realitzat nosaltres:\n",
    "\n",
    "- El BoostingClassifier sembla tenir un rendiment més equilibrat en comparació amb RandomForest, AdaBoost i Bagging.\n",
    "\n",
    "- Mentre que RandomForest mostra un rendiment excepcional al conjunt d'entrenament, el BoostingClassifier aconsegueix un equilibri entre precisió i recall al conjunt de prova.\n",
    "\n",
    "- AdaBoost i Bagging també aconsegueixen un equilibri en termes de recall i precisió, però el rendiment general no és tan alt com el BoostingClassifier.\n",
    "\n",
    "\n",
    "- En el nostre cas, el BoostingClassifier sembla una opció més sòlida en aquest conjunt de dades comparant-lo amb els altres models, aconseguint un bon equilibri entre diferents mètriques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d95152",
   "metadata": {},
   "source": [
    "## Entrega: 11 de Desembre de 2023, 23:59"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
