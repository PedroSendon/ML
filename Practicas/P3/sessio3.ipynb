{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f0b320a",
   "metadata": {},
   "source": [
    "# Sessi√≥ 3: Boosting Classifier Model\n",
    "\n",
    "La sessi√≥ consisteix en crear un boosting classifier amb _decision trees_ de la llibreria sklearn com a _weak model_. \n",
    "\n",
    "Boosting (https://en.wikipedia.org/wiki/Boosting_(machine_learning)): t√®cnica d'aprenentatge autom√†tic que consiteix en entrenar m√∫ltiples models (_weak models_) seq√ºencialment per obtenir un model general _strong model_. Podem definir un _weak learner_ o _weak model_ com un classificador el qual est√† lleugerament correlacionat amb problema final i que √©s millor que intentar-ho encertar aleat√≤riament, √©s a dir, que no ha de veure tot el problema sener. La idea √©s que cada _weak model_ es centra en una feature concreta o en arreglar els errors del classificador anterior.\n",
    "\n",
    "En ess√®ncia, el _boosting_ respon a la pregunta seg√ºent:\n",
    "\n",
    "```Can a set of weak learners create a strong single learner? ```\n",
    "\n",
    "La resposta a aquesta pregunta es **s√≠**, i ho veurem en aquesta sessi√≥.\n",
    "\n",
    "En el cas concret dels **classificadors** el que hem d'aconseguir √©s el seg√ºent: \n",
    "```\n",
    "[...] most boosting algorithms consist of iteratively learning weak classifiers with respect to a distribution and adding them to a final strong classifier. When they are added, they are weighted in a way that is related to the weak learners' accuracy. After a weak learner is added, the data weights are readjusted, known as \"re-weighting\". Misclassified input data gain a higher weight and examples that are classified correctly lose weight.[note 1] Thus, future weak learners focus more on the examples that previous weak learners misclassified._\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bda4d9",
   "metadata": {},
   "source": [
    "## Context\n",
    "\n",
    "El dataset en q√ºesti√≥ (https://www.kaggle.com/datasets/anmolkumar/health-insurance-cross-sell-prediction) √©s un dataset d'asseguran√ßes, el qual vol predir si els seus actuals clients estarien interessats en tamb√© adquirir una *asseguran√ßa de cotxe*. √âs a dir, de cilents ja existents d'una asseguradora, quina √©s la probabilitat de que els hi interessi adquirir una asseguran√ßa de cotxe per al seu vehicle. Anem a explorar el Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42573017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(304887, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Driving_License</th>\n",
       "      <th>Region_Code</th>\n",
       "      <th>Previously_Insured</th>\n",
       "      <th>Vehicle_Age</th>\n",
       "      <th>Vehicle_Damage</th>\n",
       "      <th>Annual_Premium</th>\n",
       "      <th>Policy_Sales_Channel</th>\n",
       "      <th>Vintage</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>339630</td>\n",
       "      <td>Male</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt; 1 Year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>44470.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>240794</td>\n",
       "      <td>Male</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2630.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>124429</td>\n",
       "      <td>Male</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2630.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>171989</td>\n",
       "      <td>Male</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>36332.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>257</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>327313</td>\n",
       "      <td>Male</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>42764.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id Gender  Age  Driving_License  Region_Code  Previously_Insured  \\\n",
       "0  339630   Male   21                1         28.0                   0   \n",
       "1  240794   Male   45                1         28.0                   0   \n",
       "2  124429   Male   71                1         41.0                   0   \n",
       "3  171989   Male   41                1         49.0                   0   \n",
       "4  327313   Male   77                1         28.0                   0   \n",
       "\n",
       "  Vehicle_Age Vehicle_Damage  Annual_Premium  Policy_Sales_Channel  Vintage  \\\n",
       "0    < 1 Year            Yes         44470.0                 152.0       11   \n",
       "1    1-2 Year            Yes          2630.0                  26.0       45   \n",
       "2    1-2 Year            Yes          2630.0                   7.0       11   \n",
       "3    1-2 Year            Yes         36332.0                 124.0      257   \n",
       "4    1-2 Year            Yes         42764.0                 122.0      298   \n",
       "\n",
       "   Response  \n",
       "0         1  \n",
       "1         0  \n",
       "2         0  \n",
       "3         1  \n",
       "4         0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Generate Baseline solution with a RandomForest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('data/train_project3.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b72bdfb",
   "metadata": {},
   "source": [
    "Fem una petita investigaci√≥ de les classes de resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7da643dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de zeros: 267573, percentual: 87.76%\n",
      "Total de uns: 37314, percentual: 12.24%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = df[\"Response\"].value_counts()\n",
    "response.plot(kind='bar', color=['blue', 'red'])\n",
    "\n",
    "zeros, ones = response[0]/df.shape[0], response[1]/df.shape[0]\n",
    "\n",
    "print(f\"Total de zeros: {response[0]}, percentual: {round(zeros,4)*100}%\")\n",
    "print(f\"Total de uns: {response[1]}, percentual: {round(ones,4)*100}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878c24fe",
   "metadata": {},
   "source": [
    "√âs a dir, ens trobem davant del que es diu un dataset desequilibrat, o b√© un _imabalanced dataset_, on hi ha moltes m√©s observacions d'una classe o de l'altra. En general, aquest no √©s un cas ideal ja que pot portar a diferents problemes. Hi ha m√∫ltiples maneres de solucionar-ho, i a la pr√†ctica us demanem que ho arregleu amb una _Weighted Binary Cross Entropy_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca35805",
   "metadata": {},
   "source": [
    "## Binary Cross Entropy o Log Loss\n",
    "\n",
    "En binari ens referim al tipus de classifici√≥ entre dues classes. Per el model saber com de b√© est√† classificant entre les dues classes, mira a l'espai n-dimensional de caracter√≠stiques com de lluny est√† el valor que ha donat a una observaci√≥. Aquesta \"dist√†ncia\" √©s el que s'anomena la _loss function_, que en el cas de la classificaci√≥ bin√†ria √©s\n",
    "\n",
    "$L_B = -\\cfrac{1}{N} \\sum_{i=0}^N[y_i log(p_i) + (1-y_i)log(1-p_i)]$, on $N$ s√≥n les observacions, $y_i$ √©s el valor de veritat i $p_i$ √©s la probabilitat predita per la mostra $i$\n",
    "\n",
    "Concretament (i com es desil¬∑la de l'expressi√≥) la formula calcula la p√®rdua (com de lluny s'ha quedat la precci√≥) comparant la probabilitat predita amb el valor real de l'observaci√≥, per tant, com m√©s lluny est√† la predicci√≥ de la veritat, pitjor p√®rdua t√© i m√©s gran √©s el valor de la funci√≥.\n",
    "\n",
    "Transpira de l'explicaci√≥ doncs, que si tenim moltes m√©s mostres d'una classe que de l'altra el valor de la funci√≥ de p√®rdua queda esbiaixat cap a la predicci√≥ d'una classe.\n",
    "\n",
    "## Weighted Binary Cross Entropy\n",
    "\n",
    "La idea √©s equilibrar el desbalan√ßeig de mostres afegint un coeficient que faci que la p√®rdua de la classe minorit√†ria tingui m√©s pes que no la de la classe majorit√†ria:\n",
    "\n",
    "$L_{WB} = -\\cfrac{1}{N} \\sum_{i=0}^N[w_1 y_i log(p_i) + w_0 (1-y_i)log(1-p_i)]; w_0 +w_1 = 1$\n",
    "\n",
    "On $w_1$ √©s el pes de la classe majorit√†ria i $w_0$ √©s el pes de la classe minorit√†ria. El pesos han de ser inversament proporcionals a les freq√º√®ncies de les classes, ergo tenint la classe minorit√†ria (1) un pes m√©s gran que la majorit√†ria (0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd9d1c1",
   "metadata": {},
   "source": [
    "## Baseline\n",
    "\n",
    "Una _baseline_ √©s una procediment de _benchmarking_ per comparar com el teu model funciona. Aquests han de ser senzills i r√†pids d'implementar, i no tenen perque ser molt millors que endevinar aleat√≤riament la resposta. S'usen per comparar amb els que hem de programar, de manera que vegem que el _boosting_ est√† millorant una aproximaci√≥ ing√®nua dins de l'aprenentatge autom√†tic i per jutjar si val la pena!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "050b9fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9967135364905686\n",
      "Precision: 0.9951186255794928\n",
      "Recall: 0.9779439352521841\n",
      "F1: 0.9864565311418686\n",
      "ROC AUC: 0.9886374794677204\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# import data\n",
    "train = pd.read_csv('data/train_project3.csv',)\n",
    "test = pd.read_csv('data/test_project3.csv')\n",
    "\n",
    "#train the model -> this is a baseline, only the simple features are used\n",
    "model = RandomForestClassifier()\n",
    "X = train[['Age','Driving_License','Annual_Premium','Vintage','Region_Code']]\n",
    "y = train['Response']\n",
    "model.fit(X,y)\n",
    "y_train = model.predict(X)\n",
    "\n",
    "accuracy = accuracy_score(y, y_train)\n",
    "precision = precision_score(y, y_train)\n",
    "recall = recall_score(y, y_train)\n",
    "f1 = f1_score(y, y_train)\n",
    "roc_auc = roc_auc_score(y, y_train)\n",
    "\n",
    "# evaluate the test set\n",
    "X_test = test[['Age', 'Driving_License', 'Annual_Premium', 'Vintage', 'Region_Code']]\n",
    "y_test = model.predict(X_test)\n",
    "\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1: {f1}\")\n",
    "print(f\"ROC AUC: {roc_auc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382e2f35",
   "metadata": {},
   "source": [
    "### PREGUNTA EXTRA: √©s el nostre model bo? Fa falta mirar-nos m√©s el problema si ja tenim m√®triques tan bones? √âs l'accuracy suficient o fa falta alguna altra m√®trica? Qu√® passaria si fessim servir l'F1 score en comptes de l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3b3abf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save our predictions in the Kaggle formats\n",
    "# evaluate the test set\n",
    "X_test = test[['Age', 'Driving_License', 'Annual_Premium', 'Vintage', 'Region_Code']]\n",
    "y_test = model.predict(X_test)\n",
    "\n",
    "\n",
    "test['Response'] = y_test\n",
    "test[['id','Response']].to_csv('my_solution.csv',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1bf0b5",
   "metadata": {},
   "source": [
    "# Tasques\n",
    "\n",
    "1. Completeu la classe _BoostingClassifier_ i els seus dos m√®todes _fit_ i _predict_ com veieu m√©s adhient per obtenir els millors resultats al Dataset.\n",
    "2. Implementeu la funci√≥ *balance_weights* per veure quin pes assigna a cada vector.\n",
    "\n",
    "La idea √©s que trobeu quin calcul d'error, quin learning rate i quin estil de predicci√≥ dona millors resultats, tamb√© com quin repartiment de pesos balan√ßeja millor el dataset. \n",
    "\n",
    "NOTA: per a que el resultat sigui el millor possible podeu tractar el dataset amb les eines apreses a les sessions 1 i 2 (tractament de categ√≤riques, mirar correlacions, estratificar el train i test...).\n",
    "\n",
    "3. Penjeu els millors resultats al Kaggle!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb09d42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "class BoostingClassifier:\n",
    "    def __init__(self, X: np.array, y: np.array, w: np.array):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.weights = w / w.sum()  # Normalize initial weights\n",
    "        self.n = X.shape[0]\n",
    "        self.trees = []  # Store weak learners\n",
    "        self.learning_rates = []\n",
    "        \n",
    "    #Entrena el clasificador amb un n√∫mero especific de models debils (num_trees).\n",
    "\n",
    "    def fit(self, num_trees, shrinkage=1.0, factor=1.0):\n",
    "        for m in range(num_trees):\n",
    "            # Se entrena un model debil\n",
    "            tree = DecisionTreeClassifier(max_depth=5)\n",
    "            tree.fit(self.X, self.y, sample_weight=self.weights)\n",
    "            predictions = tree.predict(self.X)\n",
    "\n",
    "            # Calcular les mostres mal clasificades\n",
    "            misclassified = predictions != self.y\n",
    "\n",
    "            #Calcular l'error de l'arbre\n",
    "            error = np.sum(self.weights * misclassified) / np.sum(self.weights)\n",
    "\n",
    "            #Actualitzar els pesos segons la predicci√≥ del model debil\n",
    "            alpha = shrinkage * np.log((1 - error) / error)\n",
    "            self.weights *= np.exp(alpha * misclassified)\n",
    "\n",
    "            #Calcular el Learning Rate\n",
    "            learning_rate = factor / (1.0 + m)\n",
    "            self.learning_rates.append(learning_rate)\n",
    "\n",
    "            #Emmagatzemar el model debil y el seu pes\n",
    "            self.trees.append((tree, alpha))\n",
    "            \n",
    "    #Realitza predicciones utilitzant el clasificador\n",
    "    def predict(self, X):\n",
    "        \n",
    "        result = np.zeros(X.shape[0])\n",
    "        \n",
    "        #Combina les prediccions de tots els models debils sumant les prediccions ponderades.\n",
    "        for tree, alpha in self.trees:\n",
    "            result += alpha * tree.predict(X)\n",
    "            \n",
    "        #Arrodoneix el resultat per obtenir predicciones binarias.\n",
    "        result_binary = np.round(result)\n",
    "        return result_binary\n",
    "    \n",
    "def balance_weights(responses: list):\n",
    "    unique_classes, counts = np.unique(responses, return_counts=True)\n",
    "    #Calcular els pesos de clase, sent inversament proporcionals a las frequencies\n",
    "    class_weights = 1.0 / counts\n",
    "    balanced = np.zeros(len(responses))\n",
    "    \n",
    "    #Assignar pesos a cada instancia basant-se en la seva classe\n",
    "    for i, c in enumerate(unique_classes):\n",
    "        balanced[responses == c] = class_weights[i]\n",
    "        \n",
    "    #Es retorna els pesos balancejats. \n",
    "    return balanced\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3af0eefa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tudu11/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/Users/tudu11/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6001180753714455\n",
      "Precision: 0.9026673507935531\n",
      "Recall: 0.6001180753714455\n",
      "F1: 0.672716248281961\n",
      "ROC AUC: 0.7795280683653147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tudu11/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Cargar los datos\n",
    "df = pd.read_csv('data/train_project3.csv')\n",
    "\n",
    "# 1. Manejo de la variable 'Vehicle_Age'\n",
    "df['Vehicle_Age'] = df['Vehicle_Age'].replace({'< 1 Year': 0, '1-2 Year': 1, '> 2 Years': 2})\n",
    "\n",
    "# 2. Codificaci√≥n de variables categ√≥ricas (por ejemplo, 'Gender' y 'Vehicle_Damage')\n",
    "encoder = OneHotEncoder(sparse=False, drop='first')\n",
    "categorical_columns = ['Gender', 'Vehicle_Damage']\n",
    "for column in categorical_columns:\n",
    "    encoded_values = encoder.fit_transform(df[[column]])\n",
    "    encoded_columns = [f\"{column}_{i}\" for i in range(encoded_values.shape[1])]\n",
    "    df = pd.concat([df, pd.DataFrame(encoded_values, columns=encoded_columns)], axis=1)\n",
    "    df.drop(columns=[column], inplace=True)\n",
    "\n",
    "# 3. Manejo de correlaciones\n",
    "correlation_matrix = df.corr().abs()\n",
    "upper_tri = correlation_matrix.where(np.triu(np.ones(correlation_matrix.shape), k=1).astype(np.bool_))\n",
    "to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.8)]\n",
    "df.drop(columns=to_drop, inplace=True)\n",
    "\n",
    "# 4. Divisi√≥n del conjunto de datos\n",
    "X = df.drop(columns=['Response'])\n",
    "y = df['Response']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# 6. Entrenar el modelo\n",
    "initial_weights = balance_weights(y_train)\n",
    "# Instantiate BoostingClassifier without the 'factor' parameter\n",
    "bc = BoostingClassifier(X_train, y_train, initial_weights)\n",
    "# Call the fit method\n",
    "bc.fit(30, shrinkage=0.1, factor=1.55)\n",
    "\n",
    "# 7. Realizar predicciones\n",
    "y_pred = bc.predict(X_test)\n",
    "\n",
    "# 8. Evaluar el modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "roc_auc = roc_auc_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "\n",
    "# Mostrar m√©tricas\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1: {f1}\")\n",
    "print(f\"ROC AUC: {roc_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcb063a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniform Weights - Accuracy: 0.7169634950309948\n",
      "Uniform Weights - Precision: 0.8866555429786178\n",
      "Uniform Weights - Recall: 0.7169634950309948\n",
      "Uniform Weights - F1: 0.7651173835754816\n",
      "Uniform Weights - ROC AUC: 0.7727750748696958\n"
     ]
    }
   ],
   "source": [
    "# Exemple d'inicialitzaci√≥ amb pesos uniformes\n",
    "initial_weights_uniform = np.ones_like(y_train) / len(y_train)\n",
    "bc_uniform = BoostingClassifier(X_train, y_train, initial_weights_uniform)\n",
    "bc_uniform.fit(30, shrinkage=0.1, factor=1.55)\n",
    "y_pred_uniform = bc_uniform.predict(X_test)\n",
    "\n",
    "# Assegura't que les prediccions i les etiquetes tinguin la mateixa longitud\n",
    "y_test_uniform = y_test[:len(y_pred_uniform)]\n",
    "\n",
    "# Avalua el rendiment\n",
    "accuracy_uniform = accuracy_score(y_test_uniform, y_pred_uniform)\n",
    "precision_uniform = precision_score(y_test_uniform, y_pred_uniform, average='weighted')\n",
    "recall_uniform = recall_score(y_test_uniform, y_pred_uniform, average='weighted')\n",
    "f1_uniform = f1_score(y_test_uniform, y_pred_uniform, average='weighted')\n",
    "roc_auc_uniform = roc_auc_score(y_test_uniform, y_pred_uniform, average='weighted')\n",
    "\n",
    "# Imprimeix o mostra les m√®triques\n",
    "print(f\"Uniform Weights - Accuracy: {accuracy_uniform}\")\n",
    "print(f\"Uniform Weights - Precision: {precision_uniform}\")\n",
    "print(f\"Uniform Weights - Recall: {recall_uniform}\")\n",
    "print(f\"Uniform Weights - F1: {f1_uniform}\")\n",
    "print(f\"Uniform Weights - ROC AUC: {roc_auc_uniform}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f9d4878",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tudu11/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# save our predictions in the Kaggle formats\n",
    "# evaluate the test set\n",
    "test = pd.read_csv('data/test_project3.csv')\n",
    "\n",
    "# 1. Manejo de la variable 'Vehicle_Age'\n",
    "test['Vehicle_Age'] = test['Vehicle_Age'].replace({'< 1 Year': 0, '1-2 Year': 1, '> 2 Years': 2})\n",
    "\n",
    "# 2. Manejo de la variable 'Vehicle_Damage'\n",
    "test = test.drop(columns=['Vehicle_Damage'])\n",
    "\n",
    "# 3. Codificaci√≥n de variables categ√≥ricas (por ejemplo, 'Gender')\n",
    "encoder = OneHotEncoder(sparse=False, drop='first')\n",
    "categorical_columns = ['Gender']\n",
    "for column in categorical_columns:\n",
    "    encoded_values = encoder.fit_transform(test[[column]])\n",
    "    encoded_columns = [f\"{column}_{i}\" for i in range(encoded_values.shape[1])]\n",
    "    test = pd.concat([test, pd.DataFrame(encoded_values, columns=encoded_columns)], axis=1)\n",
    "    test.drop(columns=[column], inplace=True)\n",
    "\n",
    "\n",
    "    \n",
    "y_test = bc.predict(test)\n",
    "\n",
    "test['Response'] = y_test\n",
    "test[['id', 'Response']].to_csv('my_solution.csv', index=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5be013",
   "metadata": {},
   "source": [
    "# Preguntes\n",
    "Per acabar, contesteu les seg√ºents preguntes:\n",
    "1. Quines m√®triques heu fet servir per avaluar els models? Com depenen aquestes m√®triques segons el balan√ß del model?\n",
    "2. Prova d'inicialitzar el model amb els pesos a $1/n$. Hi ha difer√®ncia entre pesos uniformes o cambiants per classe?\n",
    "3. Descriu breument l'estrat√®gia d'actualitzar pesos, calcul d'errors, calcul de learning rate i predicci√≥ final. Investiga quines s√≥n les estrat√®gies que utilitza el model AdaBoost i discuteix com de similars s√≥n les teves.\n",
    "4. Distuteix i compara els resultats amb els seg√ºents models de baseline: RandomForest, Bagging i AdaBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3703072",
   "metadata": {},
   "source": [
    "# --- Respostes Preguntes ---\n",
    "## 1.\n",
    "\n",
    "He utilitzat diverses m√®triques per avaluar els models, i aqu√≠ hi ha algunes de les m√®triques clau esmentades en els resultats:\n",
    "- Accuracy (Precisi√≥): Mesura la proporci√≥ de prediccions correctes al conjunt de dades.En un conjunt de dades balancejat, es una m√®trica informativa per√≤ en un desbalancejat pot ser enganyosa ja que un model que prediu sempre la classe majorit√†ria pot tenir una alta accuracy, per√≤ no proporciona informaci√≥ √∫til sobre la capacitat del model per predir la classe minorit√†ria.\n",
    "\n",
    "- Precision (Precisi√≥): Mesura la proporci√≥ d'inst√†ncies positives correctament predites entre totes les inst√†ncies que el model va predir com a positives. En un conjunt de dades desbalancejat pot ser alta inclus si un modle prediu poques instancies positives verdaderes, ja que es centra en les prediccions posotives.\n",
    "\n",
    "- Recall (Recuperaci√≥ o Sensibilitat): Mesura la proporci√≥ d'inst√†ncies positives correctament predites entre totes les inst√†ncies positives reals. En un conjunt de dades desbalancejat pot ser baix si el model tendeix a prediure la clase majoritaria, ja que es centre en instancies positives reals.\n",
    "\n",
    "- F1-Score: √âs la mitjana harm√≤nica de precisi√≥ i recall. Proporciona un equilibri entre precisi√≥ i recall. \n",
    "\n",
    "- ROC AUC (√Ärea sota la corba ROC): Mesura la capacitat del model per distingir entre classes positives i negatives. Com m√©s gran sigui el ROC AUC, millor √©s el model en aquest aspecte. No es veu afectat per el desbalancement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5080063",
   "metadata": {},
   "source": [
    "## 2. \n",
    "S√≠, hi ha difer√®ncia entre inicialitzar el model amb pesos uniformes (1/ùëõ) i inicialitzar-lo amb pesos cambiants per classe. A continuaci√≥, es destaquen algunes de les principals difer√®ncies observades en les m√®triques:\n",
    "\n",
    "Pesos Uniformes (1/ùëõ):\n",
    "\n",
    "Accuracy: 60.0%\n",
    "\n",
    "Precision: 90.3%\n",
    "\n",
    "Recall: 60.0%\n",
    "\n",
    "F1 Score: 67.3%\n",
    "\n",
    "ROC AUC: 77.95%\n",
    "\n",
    "Pesos Cambiants per Classe:\n",
    "\n",
    "Accuracy: 71.7%\n",
    "\n",
    "Precision: 88.7%\n",
    "\n",
    "Recall: 71.7%\n",
    "\n",
    "F1 Score: 76.5%\n",
    "\n",
    "ROC AUC: 77.28%\n",
    "\n",
    "Amb pesos cambiants per classe, s'observa una millora en l'accuracy, el recall i l'F1 score en comparaci√≥ amb els pesos uniformes. Aix√≤ indica que la inicialitzaci√≥ dels pesos influeix en el rendiment del model. En aquest cas, els pesos cambiants per classe semblen millorar la capacitat del model per identificar correctament les inst√†ncies positives (recall) sense sacrificar excessivament la precision.\n",
    "\n",
    "En resum, la tria de com inicialitzar els pesos pot tenir un impacte significatiu en el rendiment del model de boosting, i √©s important ajustar-ho segons les caracter√≠stiques espec√≠fiques del conjunt de dades i els objectius del model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a3df16",
   "metadata": {},
   "source": [
    "## 3.\n",
    "\n",
    "L'estrat√®gia de boosting implica l'entrenament iteratiu de models febles amb la finalitat de millorar el rendiment global d'un model fort. Aqu√≠ est√† la descripci√≥ general de l'estrat√®gia d'actualitzaci√≥ de pesos, el c√†lcul d'errors, el c√†lcul de learning rate i la predicci√≥ final:\n",
    "\n",
    "#### Entrenament de Models Febles:\n",
    "\n",
    "Es comen√ßa amb la inicialitzaci√≥ d'uns pesos per a cada observaci√≥ del conjunt de dades.\n",
    "S'entrena un model feble (com un arbre de decisi√≥ amb poca profunditat) utilitzant aquest conjunt de dades amb pesos actualitzats.\n",
    "\n",
    "El model feble es centra en corregir els errors dels models anteriors o en donar import√†ncia a les inst√†ncies mal classificades.\n",
    "\n",
    "#### C√†lcul d'Errors:\n",
    "\n",
    "Despr√©s de l'entrenament del model feble, es calcula l'error en comparaci√≥ amb les etiquetes reals.\n",
    "Les inst√†ncies mal classificades tenen un pes m√©s gran en el c√†lcul de l'error.\n",
    "\n",
    "#### Actualitzaci√≥ de Pesos:\n",
    "\n",
    "Es calcula un factor d'actualitzaci√≥ de pesos basat en l'error del model feble. Aquest factor s'utilitza per donar m√©s pes a les inst√†ncies mal classificades i menys pes a les inst√†ncies correctament classificades.\n",
    "Els pesos actualitzats es multipliquen pel factor d'actualitzaci√≥.\n",
    "\n",
    "#### C√†lcul de Learning Rate:\n",
    "\n",
    "Es calcula el learning rate, que √©s un factor que controla la contribuci√≥ de cada model feble al model global.\n",
    "El learning rate redueix la contribuci√≥ de cada model per evitar sobreajustar el conjunt d'entrenament.\n",
    "\n",
    "#### Predicci√≥ Final:\n",
    "\n",
    "Es combinen els models febles entrenats mitjan√ßant la suma ponderada de les seves prediccions.\n",
    "Els models que tenen un rendiment millor reben m√©s pes en la predicci√≥ final, mentre que els que tenen un rendiment pitjor reben menys pes.\n",
    "\n",
    "Pel que fa a AdaBoost, √©s un algoritme de boosting que utilitza una estrat√®gia similar, per√≤ amb algunes difer√®ncies notables:\n",
    "\n",
    "Pesos Inicials: AdaBoost inicialitza els pesos com a 1/n, on n √©s el nombre d'observacions.\n",
    "\n",
    "Actualitzaci√≥ de Pesos: Els pesos es redueixen per a les observacions que s'han classificat correctament i s'incrementen per a les mal classificades. Els pesos actualitzats estan relacionats amb l'error del model.\n",
    "\n",
    "C√†lcul de Learning Rate: El learning rate s'ajusta en cada iteraci√≥ basant-se en l'error del model actual.\n",
    "\n",
    "Predicci√≥ Final: La predicci√≥ final √©s la suma ponderada de les prediccions dels models febles, cada una multiplicant-se pel seu pes.\n",
    "\n",
    "Tot i que l'estrat√®gia general √©s similar, l'√∫s espec√≠fic de pesos, la manera de calcular-los i d'ajustar-los pot variar entre diferents implementacions de boosting. Les difer√®ncies es destaquen en com s'assignen i actualitzen els pesos, com es calcula el learning rate i com es combinen les prediccions finals. La teva implementaci√≥ de boosting pot tenir algunes variacions en comparaci√≥ amb AdaBoost, especialment si has adaptat el m√®tode segons les teves necessitats espec√≠fiques.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9034c72f",
   "metadata": {},
   "source": [
    "## 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc6a29d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest - Training Set:\n",
      "Accuracy: 0.9971423768700622\n",
      "Precision: 0.9958579479866911\n",
      "Recall: 0.9807737319022303\n",
      "F1: 0.988258284058557\n",
      "ROC AUC: 0.9901018218861064\n",
      "\n",
      "RandomForest - Test Set:\n",
      "Accuracy: 0.8651808849093116\n",
      "Precision: 0.21134751773049645\n",
      "Recall: 0.04023221277170244\n",
      "F1: 0.06759668821594646\n",
      "ROC AUC: 0.509737356689187\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Importar datos\n",
    "train = pd.read_csv('data/train_project3.csv')\n",
    "test = pd.read_csv('data/test_project3.csv')\n",
    "\n",
    "#train the model -> this is a baseline, only the simple features are used\n",
    "X = train[['Age', 'Driving_License', 'Annual_Premium', 'Vintage', 'Region_Code']]\n",
    "y = train['Response']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "precision_train = precision_score(y_train, y_train_pred)\n",
    "recall_train = recall_score(y_train, y_train_pred)\n",
    "f1_train = f1_score(y_train, y_train_pred)\n",
    "roc_auc_train = roc_auc_score(y_train, y_train_pred)\n",
    "\n",
    "\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "precision_test = precision_score(y_test, y_test_pred)\n",
    "recall_test = recall_score(y_test, y_test_pred)\n",
    "f1_test = f1_score(y_test, y_test_pred)\n",
    "roc_auc_test = roc_auc_score(y_test, y_test_pred)\n",
    "\n",
    "# Imprimir m√©tricas\n",
    "print(\"RandomForest - Training Set:\")\n",
    "print(f\"Accuracy: {accuracy_train}\")\n",
    "print(f\"Precision: {precision_train}\")\n",
    "print(f\"Recall: {recall_train}\")\n",
    "print(f\"F1: {f1_train}\")\n",
    "print(f\"ROC AUC: {roc_auc_train}\")\n",
    "\n",
    "print(\"\\nRandomForest - Test Set:\")\n",
    "print(f\"Accuracy: {accuracy_test}\")\n",
    "print(f\"Precision: {precision_test}\")\n",
    "print(f\"Recall: {recall_test}\")\n",
    "print(f\"F1: {f1_test}\")\n",
    "print(f\"ROC AUC: {roc_auc_test}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f95be639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost Classifier - Training Set:\n",
      "Accuracy: 0.8778273864433047\n",
      "Precision: 0.652542372881356\n",
      "Recall: 0.007723944227104022\n",
      "F1: 0.015267175572519085\n",
      "ROC AUC: 0.5035745916217809\n",
      "\n",
      "Adaboost Classifier - Test Set:\n",
      "Accuracy: 0.8778083899111155\n",
      "Precision: 0.23809523809523808\n",
      "Recall: 0.0027001485081679494\n",
      "F1: 0.005339741022560406\n",
      "ROC AUC: 0.5007527361420457\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Importar datos\n",
    "train = pd.read_csv('data/train_project3.csv')\n",
    "test = pd.read_csv('data/test_project3.csv')\n",
    "\n",
    "#train the model -> this is a baseline, only the simple features are used\n",
    "X = train[['Age', 'Driving_License', 'Annual_Premium', 'Vintage', 'Region_Code']]\n",
    "y = train['Response']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "base_model = DecisionTreeClassifier(max_depth=5)\n",
    "adaboost_model = AdaBoostClassifier(base_model, n_estimators=30, random_state=42)\n",
    "\n",
    "\n",
    "adaboost_model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = adaboost_model.predict(X_train)\n",
    "y_test_pred = adaboost_model.predict(X_test)\n",
    "\n",
    "\n",
    "accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "precision_train = precision_score(y_train, y_train_pred)\n",
    "recall_train = recall_score(y_train, y_train_pred)\n",
    "f1_train = f1_score(y_train, y_train_pred)\n",
    "roc_auc_train = roc_auc_score(y_train, y_train_pred)\n",
    "\n",
    "\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "precision_test = precision_score(y_test, y_test_pred)\n",
    "recall_test = recall_score(y_test, y_test_pred)\n",
    "f1_test = f1_score(y_test, y_test_pred)\n",
    "roc_auc_test = roc_auc_score(y_test, y_test_pred)\n",
    "\n",
    "# Imprimir m√©tricas\n",
    "print(\"Adaboost Classifier - Training Set:\")\n",
    "print(f\"Accuracy: {accuracy_train}\")\n",
    "print(f\"Precision: {precision_train}\")\n",
    "print(f\"Recall: {recall_train}\")\n",
    "print(f\"F1: {f1_train}\")\n",
    "print(f\"ROC AUC: {roc_auc_train}\")\n",
    "\n",
    "print(\"\\nAdaboost Classifier - Test Set:\")\n",
    "print(f\"Accuracy: {accuracy_test}\")\n",
    "print(f\"Precision: {precision_test}\")\n",
    "print(f\"Recall: {recall_test}\")\n",
    "print(f\"F1: {f1_test}\")\n",
    "print(f\"ROC AUC: {roc_auc_test}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07cb02c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Classifier - Training Set:\n",
      "Accuracy: 0.615368846578027\n",
      "Precision: 0.21380206000895657\n",
      "Recall: 0.7981743404554118\n",
      "F1: 0.3372634345175442\n",
      "ROC AUC: 0.6939979654539188\n",
      "\n",
      "Bagging Classifier - Test Set:\n",
      "Accuracy: 0.6057266555151039\n",
      "Precision: 0.1999783573206363\n",
      "Recall: 0.7484811664641555\n",
      "F1: 0.3156276686592656\n",
      "ROC AUC: 0.6672349271868294\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Importar datos\n",
    "train = pd.read_csv('data/train_project3.csv')\n",
    "test = pd.read_csv('data/test_project3.csv')\n",
    "\n",
    "#train the model -> this is a baseline, only the simple features are used\n",
    "X = train[['Age', 'Driving_License', 'Annual_Premium', 'Vintage', 'Region_Code']]\n",
    "y = train['Response']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "base_model = DecisionTreeClassifier(max_depth=10, class_weight='balanced', random_state=42)\n",
    "bagging_model = BaggingClassifier(base_model, n_estimators=50, random_state=42)\n",
    "\n",
    "\n",
    "bagging_model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = bagging_model.predict(X_train)\n",
    "y_test_pred = bagging_model.predict(X_test)\n",
    "\n",
    "\n",
    "accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "precision_train = precision_score(y_train, y_train_pred)\n",
    "recall_train = recall_score(y_train, y_train_pred)\n",
    "f1_train = f1_score(y_train, y_train_pred)\n",
    "roc_auc_train = roc_auc_score(y_train, y_train_pred)\n",
    "\n",
    "\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "precision_test = precision_score(y_test, y_test_pred)\n",
    "recall_test = recall_score(y_test, y_test_pred)\n",
    "f1_test = f1_score(y_test, y_test_pred)\n",
    "roc_auc_test = roc_auc_score(y_test, y_test_pred)\n",
    "\n",
    "# Imprimir m√©tricas\n",
    "print(\"Bagging Classifier - Training Set:\")\n",
    "print(f\"Accuracy: {accuracy_train}\")\n",
    "print(f\"Precision: {precision_train}\")\n",
    "print(f\"Recall: {recall_train}\")\n",
    "print(f\"F1: {f1_train}\")\n",
    "print(f\"ROC AUC: {roc_auc_train}\")\n",
    "\n",
    "print(\"\\nBagging Classifier - Test Set:\")\n",
    "print(f\"Accuracy: {accuracy_test}\")\n",
    "print(f\"Precision: {precision_test}\")\n",
    "print(f\"Recall: {recall_test}\")\n",
    "print(f\"F1: {f1_test}\")\n",
    "print(f\"ROC AUC: {roc_auc_test}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49337f5",
   "metadata": {},
   "source": [
    "En resum, aquets son els resultats:\n",
    "\n",
    "# Random forest\n",
    "### RandomForest - Training Set:\n",
    "\n",
    "Accuracy: 0.9971423768700622\n",
    "\n",
    "Precision: 0.9958579479866911\n",
    "\n",
    "Recall: 0.9807737319022303\n",
    "\n",
    "F1: 0.988258284058557\n",
    "\n",
    "ROC AUC: 0.9901018218861064\n",
    "\n",
    "### RandomForest - Test Set:\n",
    "Accuracy: 0.8651808849093116\n",
    "\n",
    "Precision: 0.21134751773049645\n",
    "\n",
    "Recall: 0.04023221277170244\n",
    "\n",
    "F1: 0.06759668821594646\n",
    "\n",
    "ROC AUC: 0.509737356689187\n",
    "\n",
    "# Adaboost classifier\n",
    "\n",
    "### Adaboost Classifier - Training Set:\n",
    "Accuracy: 0.8778273864433047\n",
    "\n",
    "Precision: 0.652542372881356\n",
    "\n",
    "Recall: 0.007723944227104022\n",
    "\n",
    "F1: 0.015267175572519085\n",
    "\n",
    "ROC AUC: 0.5035745916217809\n",
    "\n",
    "### Adaboost Classifier - Test Set:\n",
    "Accuracy: 0.8778083899111155\n",
    "\n",
    "Precision: 0.23809523809523808\n",
    "\n",
    "Recall: 0.0027001485081679494\n",
    "\n",
    "F1: 0.005339741022560406\n",
    "\n",
    "ROC AUC: 0.5007527361420457\n",
    "\n",
    "# Bagging classifier\n",
    "\n",
    "### Bagging Classifier - Training Set:\n",
    "Accuracy: 0.615368846578027\n",
    "\n",
    "Precision: 0.21380206000895657\n",
    "\n",
    "Recall: 0.7981743404554118\n",
    "\n",
    "F1: 0.3372634345175442\n",
    "\n",
    "ROC AUC: 0.6939979654539188\n",
    "\n",
    "### Bagging Classifier - Test Set:\n",
    "Accuracy: 0.6057266555151039\n",
    "\n",
    "Precision: 0.1999783573206363\n",
    "\n",
    "Recall: 0.7484811664641555\n",
    "\n",
    "F1: 0.3156276686592656\n",
    "\n",
    "ROC AUC: 0.6672349271868294"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae671073",
   "metadata": {},
   "source": [
    "Una vegada tenim tots els resultats podem comparar-los amb el BoostingClassifier que hem realitzat nosaltres:\n",
    "\n",
    "- El BoostingClassifier sembla tenir un rendiment m√©s equilibrat en comparaci√≥ amb RandomForest, AdaBoost i Bagging.\n",
    "\n",
    "- Mentre que RandomForest mostra un rendiment excepcional al conjunt d'entrenament, el BoostingClassifier aconsegueix un equilibri entre precisi√≥ i recall al conjunt de prova.\n",
    "\n",
    "- AdaBoost i Bagging tamb√© aconsegueixen un equilibri en termes de recall i precisi√≥, per√≤ el rendiment general no √©s tan alt com el BoostingClassifier.\n",
    "\n",
    "\n",
    "- En el nostre cas, el BoostingClassifier sembla una opci√≥ m√©s s√≤lida en aquest conjunt de dades comparant-lo amb els altres models, aconseguint un bon equilibri entre diferents m√®triques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d95152",
   "metadata": {},
   "source": [
    "## Entrega: 11 de Desembre de 2023, 23:59"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
